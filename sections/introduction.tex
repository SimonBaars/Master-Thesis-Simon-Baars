\chapter{Introduction}
%\todo[inline,color=blue!10]{Context: what is the bigger scope of the problem you are trying to solve? Try to connect to societal/economic challenges.
%Problem Analysis: Here you present your analysis of the problem situation that your research will address.
%How does this problem manifest itself at your host organization?
%Also summarises existing scientific insight into the problem.}
\label{ch:introduction}
Refactoring is the process of restructuring code to improve quality-related attributes of a codebase (maintainability, performance, etc.) without changing the functionality. Many methods have been introduced to help with the process of refactoring \cite{fowler2018refactoring, wake2004refactoring}. However, most of these methods still require a manual assessment of where and when to apply them. Because of this, refactoring takes up a signification portion of the development process \cite{lientz1978characteristics, mens2004survey}, or does not happen at all \cite{mens2003refactoring}. %For a large part, refactoring requires domain knowledge to do it right. However, there are also refactoring opportunities that are rather trivial and repetitive to execute. In this thesis, we take a look at the challenges and opportunities in automatically refactoring duplicated code, also known as ``code clones''. The main goal is to improve the maintainability of the refactored code.

Duplication in source code is often seen as one of the most harmful types of technical debt. If the clone is altered at one location to correct an erroneous behavior, you cannot be sure that this correction is applied to all the cloned code as well \cite{ostberg2014automatically}. Additionally, the codebase size increases unnecessarily and so increases the amount of code to be handled when conducting maintenance work, as code clones can contribute up to 25\% of the code size \cite{bruntink2005use}.

\todo{A paragraph about current clone types being ill-defined for automated refactoring}

In this study, we use refactoring techniques to automatically reduce duplication in software systems. This allows us to obtain before- and after-refactoring snapshots of software systems. We use software maintainability metrics to measure the impact of refactoring clones. We also look into what variability we can allow between code fragments to still consider them clones, while still improving maintainability when refactoring these clones. Furthermore, we look into the thresholds that should be used while detecting clones to find clones that should be refactored.

We perform several quantitative experiments on a large corpus of open-source software to collect statistical data. With these experiments, we map the context of clones: where they reside in the codebase and what the relation is between duplicate fragments. We use the results to find appropriate refactoring opportunities for specific clones. We then automate the process of applying such refactorings, to be able to measure the impact on maintainability when refactoring clones found by certain definitions and thresholds.

\section{Problem statement}
In this section, we describe the problem we address in this study and the research questions that we answer to contribute to solving the problem.

\subsection{The problem}
The maintainability of a codebase has a large impact on the time and effort spent on building the desired software system \cite{bakota2012cost, munson1978software}. The maintainability of software is one of the factors to be kept under control to avoid major delays and unexpected costs as the outcome of a software project \cite{fowler2018refactoring}. One factor that has a major impact on the maintainability of a software system is the amount of duplicate code present in a codebase \cite{heitlager2007practical, fowler1999refactoring}.

The process of improving maintainability through the refactoring of duplicate code is time-consuming and error-prone. This process mainly consists of two aspects:
\begin{itemize}
	\item Find refactoring candidates, either tool-assisted or fully manually.
	\item Refactor identified candidates, either tool-assisted or fully manually.
\end{itemize}
Clone detection tools are configured using a predefined amount of lines or tokens that two duplicate fragments should minimally span for them to be considered clones \cite{sajnani2016sourcerercc, svajlenko2016bigcloneeval}. Often, such thresholds are intuitively chosen \cite{li2006cp, roy2009mutation}, leading to a potentially non-optimal selection of clones that are presented to the developer.

A study by Batova et al. \cite{bavota2012does} shows that the process of refactoring often leaves side effects in the code. This study reports that refactorings moving components in the inheritance hierarchy of object-oriented software tend to induce faults very frequently. This suggests that more accurate code inspection or testing activities are needed when such refactoring techniques are performed. Those refactoring techniques often have to be used when dealing with duplication in software \cite{fowler2018refactoring, fontana2015duplicated}. Because of that, refactoring code clones has been empirically proven to cause bugs or other side effects in code.

\subsection{Research questions}
There is a lot of research on the topic of code clone detection. This research often results in tools that can detect clones by several clone type definitions. However, there is no research yet that looks into how these definitions align with refactoring opportunities. We align clone type definitions as used in literature \cite{roy2007survey} with their corresponding refactoring methods \cite{fowler2018refactoring} and address the shortcomings of these definitions regarding automated refactoring. This results in the following research question:
\begin{displayquote}
\textbf{Research Question 1:}\\How can we define clone types such that they \textbf{can} be automatically refactored?
\end{displayquote}
As a result, we formulate clone type definitions that can be refactored. Based on these results we perform analyses on the context of clones by these definitions. The context of a clone (the relation between cloned fragments, location of cloned fragments, etc.) has a big impact on how a clone should be refactored. We create categories by which we map the context of clones and perform statistical analyses on them. This results in the following research question:
\begin{displayquote}
\textbf{Research Question 2:}\\How can we prioritize refactoring opportunities based on the \textbf{context} of clones?
\end{displayquote}
This research question results in a prioritization of refactoring opportunities: \textit{with what refactoring method can what percentage of clones be refactored?} As a result of these first two research questions, we have clone type definitions that can be refactored together with a prioritization of the refactoring methods that can be used. Based on this prioritization, we build a tool that automatically refactors a subset of the detected clones.

Not in all cases will refactoring duplicated code result in a more maintainable codebase. Because of that, we compare the refactored code to the original code and measure the difference in maintainability. To do this, we use a practical model consisting of metrics to measure maintainability \cite{heitlager2007practical}. Based on this, we look into what \textit{thresholds} result in better maintainable code when refactored. This results in our final research question:
\begin{displayquote}
\textbf{Research Question 3:}\\What are the discriminating factors to decide when a clone \textbf{should} be refactored?
\end{displayquote}

\subsection{Research method}
We perform an \textbf{exploratory} study to look into the opportunities to automatically refactor code clones. To do this, we combine knowledge from literature with our own experience to develop definitions for refactorable clones. We also develop a tool to detect, analyze and refactor such clones. Using this tool, we perform \textbf{quantitative} experiments in which we statistically collect information about duplication in open-source software. In these experiments, we control several variables to see their impact on the results. During this process, we explore concepts and develop understanding, because of which decisions in the study design are based on the results of the experiments.

\section{Contributions}
Many studies report that code clones negatively affect maintainability \cite{heitlager2007practical, monden2002software, juergens2009code, chatterji2013effects}. However, no studies yet show in what cases code clones can reduce maintainability in source code. Refactoring often includes tradeoffs between design alternatives. With some code clones, the refactored alternative is less maintainable than keeping the duplication \cite{kapser2006cloning, aversano2007clones, hotta2010duplicate, kim2005empirical, krinke2007study, saha2010evaluating}. In this study, we analyze the maintainability of refactored code clones to improve the suggestion of code clones that should be refactored. This assists with both the identification and refactoring of code clones.

\subsection{Identification}
There are many tools to detect clones. The goal of most of these tools is to assist developers in reducing duplication in their code, i.e. assisting in the refactoring process. The problem is that these tools have no insight in the impact of refactoring such clones on the maintainability of the software. In this study, we can analyze a before- and after-refactoring snapshot of the code to determine the impact. If the maintainability increases after refactoring, this gives a strong indication that the clone should be refactored. This way the results of our study can support the clone identification process.

\subsection{Refactoring}
The tool that results from this research can assist in the process of applying refactorings to clones. The tool will only apply a refactoring if the clone is refactorable and the maintainability of the source code increases as a result of applying the refactoring. The tool applies only refactorings that do not, in any way, influence the functional correctness of the program. Because of this, potential bugs as a result of refactoring can be avoided \cite{bavota2012does}.

\section{Scope}
In this study, we perform research efforts to be able to detect refactorable clones. We will apply refactoring techniques to a subset of these clones and analyze the maintainability of the resulting source code.

\subsection{Java}
This research is limited to object-oriented programming languages. We relate our research to the most popular object-oriented programming languages (Python, Java, C\#). Our experiments and results have been conducted in the Java programming language because many refactoring practices are language-specific.

\subsection{Measuring Maintainability}
There is a lot of study on what metrics to consider to measure maintainability. In this study, we focus solely on the practical maintainability model by Heitlager et al. \cite{heitlager2007practical}. We consider the maintainability scores described in that paper as a sufficiently accurate indication of maintainability. This will be used to quantitatively determine the impact on maintainability when applying refactoring techniques to code clones.

\subsection{Naming Declarations}
Our automated refactoring model can create new methods, classes and interfaces when refactoring clones. Each of these declarations needs to have a name. Because the quality of the name will not have an impact on the maintainability metrics we use, finding appropriate names for automatically refactored code fragments is out of the scope for this study. For our automated refactoring efforts, we will use generated names for these declarations. %This may decrease the usefulness of the results of this research for refactoring-assistance.

\subsection{Testcode}
It is very disputable whether unit tests are subject to the same maintainability metrics that apply to the functional code. Because of that, for this research, unit tests are not taken into scope. The findings of this research may apply to test classes, but we will not argue the validity. Furthermore, any other code than the production code of the system will not be taken into account. In Section~\ref{chap:corpus} we describe what classes we perform our experiments on.

\section{Outline}
In Chapter~\ref{ch:background} we describe the background of this thesis. In Chapter~\ref{chap:clonetypes} we list shortcomings with established clone definitions which make them less suitable for automated refactoring. We also propose a set of clone type definitions that strive to solve these shortcomings. In Chapter~\ref{ch:clonerefactor} we propose a tool to detect, analyze and automatically refactor such clones that can be refactored. Using this tool we perform a set of experiments, of which the setup is explained in Chapter~\ref{ch:experimentalsetup}. The results of the experiments are in shown in Chapter~\ref{ch:results} and discussed in Chapter~\ref{ch:discussion}. Chapter~\ref{ch:related_work} contains the work related to this thesis. Finally, we present our concluding remarks in Chapter~\ref{ch:conclusion} together with future work.
