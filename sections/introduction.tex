\chapter{Introduction}
%\todo[inline,color=blue!10]{Context: what is the bigger scope of the problem you are trying to solve? Try to connect to societal/economical challenges.
%Problem Analysis: Here you present your analysis of the problem situation that your research will address.
%How does this problem manifest itself at your host organisation?
%Also summarises existing scientific insight into the problem.}
\label{ch:introduction}
Refactoring is used to improve quality related attributes of a codebase (maintainability, performance, etc.) without changing the functionality. There are many methods that have been introduced to help with the process of refactoring \cite{fowler2018refactoring, wake2004refactoring}. However, most of these methods still require manual assessment of where and when to apply them. Because of this, refactoring takes up a signification portion of the development process \cite{lientz1978characteristics, mens2004survey}, or does not happen at all \cite{mens2003refactoring}. For a large part, refactoring requires domain knowledge to do it right. However, there are also refactoring opportunities that are rather trivial and repetitive to execute. In this thesis, we take a look at the challenges and opportunities in automatically refactoring duplicated code, also known as ``code clones''. The main goal is to improve maintainability of the refactored code.

Duplication in source code is often seen as one of the most harmful types of technical debt. \textit{``Clones are problematic for the maintainability of a program, because if the clone is altered at one location to correct an erroneous behaviour, you cannot be sure that this correction is applied to all the cloned code as well. Additionally, the code base size increases unnecessarily and so increases the amount of code to be handled when conducting maintenance work''} \cite{ostberg2014automatically}. Bruntink et al.~\cite{bruntink2005use} show that code clones can contribute up to 25\% of the code size.

In this study, we use refactoring techniques to automatically reduce duplication in software systems. This allows us to obtain before- and after-refactoring snapshots of software systems. We use software maintainability metrics to measure the impact of refactoring clones. This way we can determine better definitions of clones. We also look into what variability we can allow between code fragments to still consider them clones, while still improving maintainability when refactoring these clones. Futhermore, we look into the thresholds that should be used while detecting clones to find clones that should be refactored.

We perform several quantitative experiments on a large corpus of open source software to collect statistical data. With these experiments we map the context of clones: where they reside in the codebase and what the relation is between duplicate fragments. We use the results to find appropriate refactoring opportunities for specific clones. We then automate the process of applying such refactorings, to be able to measure the impact on maintainability when refactoring clones found by certain definitions and thresholds.

\section{Problem statement}
In this section we describe the problem we address with this study and the research questions that we answer in order to contribute to solving the problem.

\subsection{The problem}
The maintainability of a codebase has a large impact on the time and effort spent on building the desired software system \cite{bakota2012cost, munson1978software}. The maintainability of software is one of the factors to be kept under control in order to avoid major delays and unexpected costs as a result of a software project \cite{fowler2018refactoring}. One factor that has a major impact on the maintainability of a software system is the amount of duplicate code present in a codebase \cite{heitlager2007practical, fowler1999refactoring}.

The process of improving maintainability through the refactoring of duplicate code is time consuming and error-prone. This process mainly consists of these two aspects:
\begin{itemize}
	\item Find refactoring candidates, either tool-assisted or manually.
	\item Refactor identified candidates, either tool-assisted or manually.
\end{itemize}
There are tools that assist in the process of finding duplicate code, but none of these tools identify all duplication problems. Often, these clone detection tools result in false-positives and false-negatives \cite{roy2007survey}. Many false-negatives are due to the thresholds that are used. Many clone detection tools \cite{sajnani2016sourcerercc, svajlenko2016bigcloneeval} only consider clones that have a minimum of 6 lines. Using such an approach is bound to result in many false-negatives.

A study by Batova et al. \cite{bavota2012does} shows that the process of refactoring often leaves side effects in the code. This study reports that refactorings involving hierarchies (e.g., pull up method), tend to induce faults very frequently. \textit{This suggests more accurate code inspection or testing activities when such specific refactorings are performed.} Such specific refactorings often have to be used when dealing with duplication in software \cite{fowler2018refactoring, fontana2015duplicated}. Because of that, refactoring code clones has been empirically proven to cause bugs or other side effects in code.

\subsection{Research questions}
There is a lot of research on the topic of code clone detection. This research often results in tools that can detect clones by several clone type definitions. However, there is no research yet that looks into how these definitions align with refactoring opportunities. We will align clone type definitions as used in literature \cite{roy2007survey} with their corresponding refactoring methods \cite{fowler2018refactoring}. For this, we answer the following research question:
\begin{displayquote}
\textbf{Research Question 1:}\\How can we define clone types such that they \textbf{can} be automatically refactored?
\end{displayquote}
As a result, we expect to formulate clone type definitions that can be refactored. On basis of this results we can perform analyses on the context of clones by these definitions. The context of a clone (location, relation between clones, etc.) has a big impact on how a clone should be refactored. We will create categories by which we map the context of clones and perform a statistical analysis on this. This results in the following research question:
\begin{displayquote}
\textbf{Research Question 2:}\\How can we prioritize refactoring opportunities based on the \textbf{context} of clones?
\end{displayquote}
We expect this research question to result in a priorization of refactoring opportunities: \textit{with what refactoring method can what percentage of clones be refactored?} As a result of these first two research questions we expect to have clone type definitions that can be refactored together with a prioritization of the refactoring methods that can be used. On basis of this we expect to be able to build a script that can automatically refactor the highest prioritized clones. With this script, we expect to be able to answer our final research question:
\begin{displayquote}
\textbf{Research Question 3:}\\What are the discriminating factors to decide when a clone \textbf{should} be refactored?
\end{displayquote}
Not in all cases will refactoring duplicated code result in a more maintainable codebase. Because of that, we compare the refactored code to the original code and measure the difference in maintainability. To do this, we will use a practical model consisting of metrics to measure maintainability \cite{heitlager2007practical}. Based on this, we can look into what \textit{thresholds} result in better maintainable code when refactored. These thresholds consist of the size of clones and the variability we can allow between cloned fragments to still consider them clones.

\subsection{Research method}
We perform an \textbf{exploratory} study to look into the opportunities to automatically refactor code clones. To do this, we combine knowledge from literature with our own experience to develop definitions for refactorable clones. We also develop a tool to detect, analyze and refactor such clones. Using this tool, we perform \textbf{quantitative} experiments in which we statistically collect information about duplication in open source software. In these experiments we control several variables to see their impact on the results. During this process we explore concepts and develop understanding, because of which decisions in the study design are based upon the results of the experiments.

\section{Contributions}
Many modern clone detection techniques and thresholds have been validated by manually assessing a sample of the results \cite{sajnani2016sourcerercc, cordy2011nicad, jiang2007deckard}. 
%Our research makes the following contributions:
%\begin{enumerate}
%	\item We deliver several novel measurements regarding code clones on a large corpus of Java projects.
%	\item We deliver a novel clone detection tool that finds refactorable clones in Java.
%	\item We deliver a novel clone refactoring tool that suggests refactorings to be applied, and applies these refactorings.
%	\item We give further recommendations in how refactoring can be automatically applied to improve maintainability in software projects.
%\end{enumerate}

\section{Scope}
In this study, we perform research efforts to be able to detect refactorable clones. We will apply refactoring techniques to a subset of these clones and analyze the maintainability of the resulting source code.

There is a lot of study on how what metrics to consider to measure maintainability. In this study, we focus solely on the practical maintainability model by Heitlager et al. \cite{heitlager2007practical}. We consider the maintainability scores described in that paper as an sufficiently accurate indication of maintainability. This will be used to quantitatively determine the impact on maintainability when applying refactoring techniques to code clones.

Applying refactoring often entails creating new method declarations, class declarations, etc. Each of these declarations needs to have a name. Because the quality of the name is not included in the maintainability metrics we use, finding appropriate names for automatically refactored code fragments is out of the scope for this study. For our automated refactoring efforts, we will use generated names for these declarations.

It is very disputable whether unit tests apply to the same maintainability metrics that applies to the functional code. Because of that, for this research, unit tests are not taken into scope. The findings of this research may be applicable to those classes, but we will not argue the validity.

\section{Outline}
In Chapter~\ref{ch:background} we describe the background of this thesis. In Chapter~\ref{chap:clonetypes} we list shortcomings with clone definitions from literature and propose a set of clone type definitions which can be automatically refactored. In Chapter \ref{ch:clonerefactor} we propose a tool to detect, analyze and automatically refactor such clones that can be refactored. Using this tool we perform a set of experiments, of which the results are shown in Chapter~\ref{ch:results} and discussed in Chapter~\ref{ch:discussion}. Chapter~\ref{ch:related_work} contains the work related to this thesis. Finally, we present our concluding remarks in Chapter~\ref{ch:conclusion} together with future work.
