\chapter{Introduction}
%\todo[inline,color=blue!10]{Context: what is the bigger scope of the problem you are trying to solve? Try to connect to societal/economical challenges.
%Problem Analysis: Here you present your analysis of the problem situation that your research will address.
%How does this problem manifest itself at your host organisation?
%Also summarises existing scientific insight into the problem.}
\label{ch:introduction}
Refactoring is the process of restructuring code to improve quality related attributes of a codebase (maintainability, performance, etc.) without changing the functionality. There are many methods that have been introduced to help with the process of refactoring \cite{fowler2018refactoring, wake2004refactoring}. However, most of these methods still require manual assessment of where and when to apply them. Because of this, refactoring takes up a signification portion of the development process \cite{lientz1978characteristics, mens2004survey}, or does not happen at all \cite{mens2003refactoring}. %For a large part, refactoring requires domain knowledge to do it right. However, there are also refactoring opportunities that are rather trivial and repetitive to execute. In this thesis, we take a look at the challenges and opportunities in automatically refactoring duplicated code, also known as ``code clones''. The main goal is to improve maintainability of the refactored code.

Duplication in source code is often seen as one of the most harmful types of technical debt. If the clone is altered at one location to correct an erroneous behaviour, you cannot be sure that this correction is applied to all the cloned code as well \cite{ostberg2014automatically}. Additionally, the code base size increases unnecessarily and so increases the amount of code to be handled when conducting maintenance work, as code clones can contribute up to 25\% of the code size \cite{bruntink2005use}.

\todo{A paragraph aboout current clone types being ill-defined for automated refactoring}

In this study, we use refactoring techniques to automatically reduce duplication in software systems. This allows us to obtain before- and after-refactoring snapshots of software systems. We use software maintainability metrics to measure the impact of refactoring clones. We also look into what variability we can allow between code fragments to still consider them clones, while still improving maintainability when refactoring these clones. Futhermore, we look into the thresholds that should be used while detecting clones to find clones that should be refactored.

We perform several quantitative experiments on a large corpus of open source software to collect statistical data. With these experiments we map the context of clones: where they reside in the codebase and what the relation is between duplicate fragments. We use the results to find appropriate refactoring opportunities for specific clones. We then automate the process of applying such refactorings, to be able to measure the impact on maintainability when refactoring clones found by certain definitions and thresholds.

\section{Problem statement}
In this section we describe the problem we address in this study and the research questions that we answer in order to contribute to solving the problem.

\subsection{The problem}
The maintainability of a codebase has a large impact on the time and effort spent on building the desired software system \cite{bakota2012cost, munson1978software}. The maintainability of software is one of the factors to be kept under control in order to avoid major delays and unexpected costs as the outcome of a software project \cite{fowler2018refactoring}. One factor that has a major impact on the maintainability of a software system is the amount of duplicate code present in a codebase \cite{heitlager2007practical, fowler1999refactoring}.

The process of improving maintainability through the refactoring of duplicate code is time consuming and error-prone. This process mainly consists of two aspects:
\begin{itemize}
	\item Find refactoring candidates, either tool-assisted or fully manually.
	\item Refactor identified candidates, either tool-assisted or fully manually.
\end{itemize}
There are tools that assist in the process of finding duplicate code, but none of these tools identify all duplication problems. Often, these clone detection tools result in false-positives and false negatives \cite{roy2007survey}. We define false negatives as clones that can and should be refactored but are not found due to the configuration by which they are detected. We define false-positives as clones that do not improve the system maintainability when refactored. Many false negatives are due to the thresholds that are used. Clone detection tools are configured using a predefined amount of lines or tokens that two duplicate fragments should minimally have for them to be considered clones \cite{sajnani2016sourcerercc, svajlenko2016bigcloneeval}. Often, such thresholds are intuitively chosen \cite{li2006cp, roy2009mutation}, leading to a potentially non-optimal selection of clones that are presented to developer.

A study by Batova et al. \cite{bavota2012does} shows that the process of refactoring often leaves side effects in the code. This study reports that refactorings moving components in the inheritance hierarchy of object-oriented software tend to induce faults very frequently. This suggests that more accurate code inspection or testing activities are needed when such refactoring techniques are performed. Those refactoring techniques often have to be used when dealing with duplication in software \cite{fowler2018refactoring, fontana2015duplicated}. Because of that, refactoring code clones has been empirically proven to cause bugs or other side effects in code.

\subsection{Research questions}
There is a lot of research on the topic of code clone detection. This research often results in tools that can detect clones by several clone type definitions. However, there is no research yet that looks into how these definitions align with refactoring opportunities. We will align clone type definitions as used in literature \cite{roy2007survey} with their corresponding refactoring methods \cite{fowler2018refactoring}. For this, we answer the following research question:
\begin{displayquote}
\textbf{Research Question 1:}\\How can we define clone types such that they \textbf{can} be automatically refactored?
\end{displayquote}
As a result, we expect to formulate clone type definitions that can be refactored. On the basis of this results we can perform analyses on the context of clones by these definitions. The context of a clone (location, relation between clones, etc.) has a big impact on how a clone should be refactored. We will create categories by which we map the context of clones and perform a statistical analysis on this. This results in the following research question:
\begin{displayquote}
\textbf{Research Question 2:}\\How can we prioritize refactoring opportunities based on the \textbf{context} of clones?
\end{displayquote}
We expect this research question to result in a priorization of refactoring opportunities: \textit{with what refactoring method can what percentage of clones be refactored?} As a result of these first two research questions we expect to have clone type definitions that can be refactored together with a prioritization of the refactoring methods that can be used. On the basis of this we expect to be able to build a script that can automatically refactor the highest prioritized clones. With this script, we expect to be able to answer our final research question:
\begin{displayquote}
\textbf{Research Question 3:}\\What are the discriminating factors to decide when a clone \textbf{should} be refactored?
\end{displayquote}
Not in all cases will refactoring duplicated code result in a more maintainable codebase. Because of that, we compare the refactored code to the original code and measure the difference in maintainability. To do this, we will use a practical model consisting of metrics to measure maintainability \cite{heitlager2007practical}. Based on this, we can look into what \textit{thresholds} result in better maintainable code when refactored. These thresholds consist of the size of clones and the variability we can allow between cloned fragments to still consider them clones.

\subsection{Research method}
We perform an \textbf{exploratory} study to look into the opportunities to automatically refactor code clones. To do this, we combine knowledge from literature with our own experience to develop definitions for refactorable clones. We also develop a tool to detect, analyze and refactor such clones. Using this tool, we perform \textbf{quantitative} experiments in which we statistically collect information about duplication in open source software. In these experiments we control several variables to see their impact on the results. During this process we explore concepts and develop understanding, because of which decisions in the study design are based upon the results of the experiments.

\section{Contributions}
Many studies report that code clones negatively affect maintainability \cite{heitlager2007practical, monden2002software, juergens2009code, chatterji2013effects}. However, no studies yet show in what cases code clones can reduce maintainability in source code. Refactoring often includes tradeoffs between design alternatives. With some code clones, the refactored alternative is less maintainable than keeping the duplication \cite{kapser2006cloning, aversano2007clones, hotta2010duplicate, kim2005empirical, krinke2007study, saha2010evaluating}. In this study, we analyze the maintainability of refactored code clones, in order to improve the suggestion of code clones that should be refactored. This assists with both the identification and refactoring of code clones.

\subsection{Identification}
There are many tools to detect clones. The goal of most of these tools is to assist developers in reducing duplication in their code, i.e. assisting in the refactoring process. The problem is that these tools have no limited % TODO: Sander -of limited of no, niet beide ;)
insight on the impact of refactoring such clones on the design of the software. In this study, we can analyze a before- and after-refactoring snapshot of the code to determine the impact. A higher maintainability after refactoring increases the support for the clone being a true-positive. This way the results of our study can support the clone identification process.

\subsection{Refactoring}
The tool that results from this research can aid in the process of applying refactorings to clones. The tool will only apply a refactoring if the clone is refactorable and the maintainability of the source code increases as a result of applying the refactoring. The tool applies only refactorings that do not, in any way, influence the functional correctness of the program. Because of this, potential bugs as a result of refactoring can be avoided \cite{bavota2012does}.

\section{Scope}
In this study, we perform research efforts to be able to detect refactorable clones. We will apply refactoring techniques to a subset of these clones and analyze the maintainability of the resulting source code.

\subsection{Java}
This research is limited to object-oriented programming languages. We relate our research to the most popular object-oriented programming languages (Python, Java, C\#). Our experiments and results have been conducted in the Java programming language, because many refactoring practises are language-specific.

\subsection{Measuring Maintainability}
There is a lot of study on how what metrics to consider to measure maintainability. In this study, we focus solely on the practical maintainability model by Heitlager et al. \cite{heitlager2007practical}. We consider the maintainability scores described in that paper as an sufficiently accurate indication of maintainability. This will be used to quantitatively determine the impact on maintainability when applying refactoring techniques to code clones.

\subsection{Naming Declarations}
By our automated refactoring model new method declarations, class declarations and interfaces are created. Each of these declarations needs to have a name. Because the quality of the name will not have an impact on the maintainability metrics we use, finding appropriate names for automatically refactored code fragments is out of the scope for this study. For our automated refactoring efforts, we will use generated names for these declarations. %This may decrease the usefulness of the results of this research for refactoring-assistance.

\subsection{Testcode}
It is very disputable whether unit tests apply to the same maintainability metrics that applies to the functional code. Because of that, for this research, unit tests are not taken into scope. The findings of this research may be applicable to those classes, but we will not argue the validity. Furthermore, any other code than the production code of the system will not be taken into account. In Section~\ref{chap:corpus} we describe what classes we perform our experiments on.

\section{Outline}
In Chapter~\ref{ch:background} we describe the background of this thesis. In Chapter~\ref{chap:clonetypes} we list shortcomings with established clone definitions which make them less suitable for automated refactoring. We also propose a set of clone type definitions that strive to solve these shortcomings. In Chapter \ref{ch:clonerefactor} we propose a tool to detect, analyze and automatically refactor such clones that can be refactored. Using this tool we perform a set of experiments, of which the setup is explained in Chapter~\ref{ch:experimentalsetup}. The results of the experiments are in shown in Chapter~\ref{ch:results} and discussed in Chapter~\ref{ch:discussion}. Chapter~\ref{ch:related_work} contains the work related to this thesis. Finally, we present our concluding remarks in Chapter~\ref{ch:conclusion} together with future work.
