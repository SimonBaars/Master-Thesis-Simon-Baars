\chapter{Conclusion}
\label{ch:conclusion}
In the research we have conducted so far we have made three novel contributions:
\begin{itemize}
    \item We proposed a method with which we can detect clones that can/should be refactored.
    \item We mapped the context of clones in a large corpus of open source systems.
    \item We mapped the opportunities to perform method extraction on clones this corpus.
\end{itemize}

We have looked into existing definitions for different types of clones \cite{roy2007survey} and proposed solutions for problems that these types have with regards to automated refactoring. We propose that fully qualified identifiers of method call signatures and type references should be considered instead of their plain text representation, to ensure refactorability. Furthermore, we propose that one should define thresholds for variability in variables, literals and method calls, in order to limit the number of parameters that the merged unit shall have.

The research that we have conducted so far analyzes the context of different kinds of clones and prioritizes their refactoring. Firstly, we looked at the inheritance relation of clone instances in a clone class. We have found that more than a third of all clone classes are flagged unrelated, which means that they have at least one instance that has no relation through inheritance with the other instances. For about a fourth of the clone classes all of its instances are in the same class. About a sixth of the clone classes have clone instances that are siblings of each other (share the same superclass).

Secondly, we looked at the location of clone instances. Most clone instances (58 percent) are found at method level. About 37 percent of clone instances were found at class level. We defined ``class level clones'' as clones that exceed the boundaries of a single method or contain something else in the class (like field declarations, other methods, etc.). Thirdly, we looked at the contents of clone instances. Most clones span a part of a method (57 percent). About 26 percent of clones span over several methods.

We also looked into the refactorability of clones that span a part of a method. Over 10 percent of the clones can directly be refactored by extracting them to a new method (and calling the method at all usages using their relation). The main reason that most clones that span a part of a method cannot directly be refactored by method extraction, is that they contain \texttt{return}, \texttt{break} or \texttt{continue} statements.

\section{Threats to validity}\label{chap:threatstovalidity}
We noticed that, when doing measurements on a corpus of this size, the thresholds that we use for the clone detection have a big impact on the results. There does not seem to be one golden set of thresholds, some thresholds work in some situations but fail in others. We have chosen thresholds that, according to our manual assessment, seemed optimal. However, by using these, we definitely miss some harmful clones.

\section{Future work} \label{sec:future_work}
This study presents a foundation for research in a largely unexplored field of studies: analyzing maintainability through automated refactoring. However, we scratched just the tip of the iceberg regarding all research opportunities in this field. In this section we describe possible extensions to this research, as well as other research opportunities in this field of studies.

\subsection{Automated Refactoring for more metrics}
In this study we presented evidence regarding the value of applying automated refactoring to analyze the before- and after state of source code and refactored source code. Analyzing these states we were able to analyze the improvement in maintainability after applying certain refactorings. This allows us to better assess thresholds by which maintainability issues in source code are identified. We also get better insights in the costs and values of applying certain refactoring efforts.

For this study we chose to focus only on the automated refactoring of duplication in source code. However, software maintainability depends on more factors and can be measured by more metrics. These factors also have opportunities to automate their refactorings. We think that several similarly sized studies can be conducted to automate the refactoring of other maintainability metrics.

A study by Heitlager et al. \cite{heitlager2007practical} presents several metrics by which the maintainability of source code can be assessed. They propose thresholds that indicate issues with these metrics. Many of these metrics have automated refactoring opportunities. In this section we will focus on several of these metrics to outline their opportunities for automated refactoring.

\subsubsection{Long parameter list}
When multiple parameters are used together in a method, there is an implicit dependency between these parameters: the dependency of being required by that method. If a lot of data hangs around really tight together, they should be made into their own object \cite{fowler1999refactoring, visser2016building}. Guidelines describe to limit the number of parameters per method to at most 4 \cite{visser2016building}.

If a method has many parameters, we can group strongly related parameters into an object. This can be done automatically, but two things must be considered:
\begin{itemize}
  \item How do we determine whether parameters are strongly related?
  \item At what other places is this data used in unison and should thus use the new abstraction?
\end{itemize}
To determine whether parameters are strongly related we must look into at what places they are used in the codebase. We must then define some threshold that denotes the percentage of usages of these variables in which they are used together. If this threshold exceeds a certain amount, we can group them into an object. We must then trace all places in which they are used together and replace the variables by the newly created abstractions.

\subsubsection{Method complexity}
Method complexity refers to the complexity of the logic in a method body. There are several methods to compute method complexity. The most used complexity metric is (MCCabe) Cyclomatic Complexity \cite{visser2016building}, which refers to the amount of independent paths that can be taken though the source code. Another complexity metric that has recently become fairly popular is Cognitive Complexity \cite{campbell2017cognitive}, which attempts to measure the human perceived complexity. Both indicate an aspect of source code maintainability.

Dealing with method complexity can largely be done by method extraction. We extract a part of a complex method to a new method. This way we split the complexity of the original method into separately testable methods. Also, the methods become easier to read.

Refactoring complex methods can largely be done automatically. Also, many of the results of this study can be reused. To assess an automated refactoring opportunity for complex methods, we should assess which parts of methods can be split to end up with parts of similar complexity. For this, our research can be used to assess whether a given piece of code can be extracted to a new method (see section \ref{sec:refactorability}).

We recommend to extend our tool, CloneRefactor, to allow for such capabilities. CloneRefactor already contains a component that calculates the Cyclomatic Complexity of a given method. Using our automated refactored model, identified problems can relatively easily be refactored.

\subsubsection{Method size}
Method size has a strong relation, in terms of refactoring, with Cyclomatic Complexity. Although method size is often related to Cyclomatic Complexity, a study by Landman et al. \cite{landman2016empirical} shows that Cyclomatic Complexity is not redundant to method size. However, they do share a similar method of refactoring. The automated refactoring opportunities described in the previous section also apply to method size.

\subsubsection{Combining the metrics}
Combining the automated refactoring models for each of these metrics can result in a model that ultimately provides significant improvement in the ease of writing well-maintainable source code. In this study, we presented a few tradeoffs that are the result of refactoring code clones. For instance, refactoring code clones with a lot of variability can result in long parameter lists. However, if we can combine this with automated refactoring of long parameter lists, this tradeoff can be mitigated. This way, it is possible to work towards an model of automated refactoring that reduces manual refactoring efforts significantly.

When programming, there are often trade-offs between technical debt and velocity. When a deadline comes near, often software quality in sacrificed to gain velocity \cite{costello1984software, austin2001effects, shah2014global}. Apart from that, a low programmer aptitude can result in low quality code \ref{cheney1984effects}. This is because often forming appropriate abstractions requires time, effort and critical thinking. By introducing these abstractions automatically, this negative impact can (partly) be mitigated.
%When programming, many developers must take decisions between velocity
%Many programmers report frequent decisions in which they decide to take technical debt

\subsection{Identifying more types/definitions for clones}
In this study, we proposed a set of clone type definitions for which a refactoring opportunity is known. We based these clone type definitions on the clone type definitions that are commonly used in literature. The design of these clone type definitions entails some decisions that have a large impact on the clones we considered for refactoring in this study.

\subsubsection{Type 2R clones}
With type 2R clones we allow variability in some identifiers and literals such that the code can and should still be refactored. For type 2R clones we chose a set of expressions in which we allow variability and proposed a recommended refactoring strategy. We think however that type 2R could still use a lot of improvement to find more duplication patterns that can be refactored.

One method we think can be used to find more refactoring opportunities is to allow variability in expressions that have/return the same type. If expressions have/return the same type, they can be extracted to a parameter and the corresponding expression can be passed as a parameter. An example of this is displayed in figure \ref{fig:samereturn}. The only thing to watch out for is method that have side effects. Because methods may be executed in another point during execution, this might affect the functionality of the code.

\begin{figure}[H]
\begin{parcolumns}{2}
\colchunk[1]{
\begin{javacode}
// Original
public void doStuff(){
  int numbers = 456;
|\highlightYellow|  doA(getTitle());
|\highlightYellow|  doB(123);
  doC();
|\highlightYellow|  doA("456");
|\highlightYellow|  doB(numbers);
}

public String getTitle(){
  return "123";
}
\end{javacode}}
\colchunk[2]{
\begin{javacode}
// Refactored
public void doStuff(){
  int numbers = 456;
|\highlightYellow|  doAandB(getTitle(), 123);
  doC();
|\highlightYellow|  doAandB("456", numbers);
}

public void doAandB(String var1, int var2){
  doA(var1);
  doB(var2);
}

public String getTitle(){
  return "123";
}
\end{javacode}}
\end{parcolumns}
\caption{Refactoring different expressions that have the same return type.}
\label{fig:samereturn}
\end{figure}

\subsubsection{Type 4 clones}
In section \ref{chap:backgroundclonetypes} we introduced the clone types that are used in literature. Of these clone types, we considered type 1, 2 and 3 for refactoring. We chose not to consider type 4 clones because they appear far less in source code and are more difficult to detect and refactor. However, that does not mean that these clones should not be refactored.

We think that there are relevant research opportunities in refactoring type 4 clones. Type 4 clones are functionally equal pieces of code that are implemented through different implementations. Although functionally equal, type 4 clones might still differ in other aspects. For instance, for type 4 clones, one alternative might be easier to maintain. Also, they can differ (significantly) in performance.

There are interesting research opportunities in automatically choosing the better alternative among type 4 clone instances.

\subsubsection{Proposing new clone type definitions}
We think that current definitions of clone types still lack in the identification of all duplication issues that a developer should invest his/her refactoring efforts in. Current clone detection techniques still result in many false positives and false negatives. By proposing good definitions for code clones that mark the characteristics of harmful anti-patterns, we can create more accurate suggestions to developers.

\subsection{Refactoring the harder to refactor clones}
In section \ref{sec:refactorability} we introduced to what extent clones can be refactored through method extraction. Because we strived to get results fast, we excluded categories that could not not be directly refactored through method extraction. However, with a few transformations or further considerations it might be possible to make these clones refactorable. In this section we will highlight a few of these categories which we believe to be refactorable through method extraction with a bit more effort.

\subsubsection{Partial block}
We did not consider clones for refactoring that span a part of a block. Although it is indeed not possible to refactor such clones, there are possibilities to make such clones refactorable.

\subsubsection{Overlap within a clone class}
We do not consider clone classes for refactoring that overlap in the clone class itself. That is because such clones might require other techniques to refactor them. We consider analyzing such refactoring methods future work. An example refactoring of clone instances that overlap within their clone class is displayed in figure \ref{fig:overlaprefactoring}. In this example one clone instance is found between line \ref{line:overlaprefactoring1} and \ref{line:overlaprefactoring4} and the other between \ref{line:overlaprefactoring2} and \ref{line:overlaprefactoring5}. To refactor such clones, other techniques may be required, like introducing a new for-loop to reduce the duplication.

\begin{figure}[H]
\begin{parcolumns}{2}
\colchunk[1]{
\begin{javacode}
// Original
public boolean sayHello(){
|\highlightYellow|  System.out.println("hello!"); |\label{line:overlaprefactoring1}|
|\highlightDarkyellow|  System.out.println("hello!"); |\label{line:overlaprefactoring2}|
|\highlightDarkyellow|  System.out.println("hello!"); |\label{line:overlaprefactoring3}|
|\highlightDarkyellow|  System.out.println("hello!"); |\label{line:overlaprefactoring4}|
|\highlightYellow|  System.out.println("hello!"); |\label{line:overlaprefactoring5}|
}
\end{javacode}}
\colchunk[2]{
\begin{javacode}
// Refactored
public boolean sayHello(){
|\highlightYellow|  for(int i = 0; i<5; i++){
|\highlightYellow|    System.out.println("hello!");
|\highlightYellow|  }
}
\end{javacode}}
\end{parcolumns}
\caption{Refactoring a clone class that has overlap within the clone class due to the clone class existing of equal lines.}
\label{fig:overlaprefactoring}
\end{figure}

\subsubsection{Complex control flow}
Break, continue and return statements can obstruct the possibility of performing method extraction. However, with some extra transformations, method extraction will still be possible in such cases. Figure \ref{fig:complexcontrolflowrefactoring} shows such a transformation. We can wrap the newly extracted method in a conditional to indicate whether the ``control flow modifying statement'' should be executed. In other cases, other methods might apply to refactor such clones.

\begin{figure}[H]
\begin{parcolumns}{2}
\colchunk[1]{
\begin{javacode}
// Original
public boolean doStuff(){
  int numbers = 456;
|\highlightYellow|  if(doA());
|\highlightYellow|    return false;
|\highlightYellow|  doB();
  doC();
|\highlightYellow|  if(doA());
|\highlightYellow|    return false;
|\highlightYellow|  doB();
  return true;
}
\end{javacode}}
\colchunk[2]{
\begin{javacode}
// Refactored
public boolean doStuff(){
  int numbers = 456;
|\highlightYellow|  if(!doAandB())
|\highlightYellow|    return false;
  doC();
|\highlightYellow|  return doAandB();
}

public boolean doAandB(){
  if(doA())
    return false;
  doB(var2);
  return true;
}
\end{javacode}}
\end{parcolumns}
\caption{Refactoring a method that is obstructed by a complex control flow.}
\label{fig:complexcontrolflowrefactoring}
\end{figure}

\subsection{Naming of refactored methods/classes/etc.}
In this study, we took naming of refactored entities out of the scope. We applied automated refactoring to duplication, and gave all generated methods, classes and interfaces generated names. For our purposes that was not much of an issue, because of the validation methods used. We validated our approach using the SIG Maintainability model, which does not take naming quality into account. Because of that, the results of our experiments are in no way dependent on the names we give the generated methods, classes and interfaces.

When using our work with the purpose of refactoring assistance, these names will have to be manually provided. However, recent studies allow assistance in this process by generating a name that matches the body of a declaration. If this can be done in a reliable way, we can apply refactorings without any manual steps required.

A study by Allamanis et al. \cite{allamanis2015suggesting} proposes a machine learning model that can suggest accurate method and class names. This study shows promising results towards generating method and class names on basis of their body and context. However, the source code of this study in not available, making it harder to apply their findings to generate class and method names for any software project.

In a recent study by Alon et al. \cite{alon2018code2seq} they propose code2seq. Code2seq is a machine learning model that guesses the name of a method given a method body. This model has been trained on a large set of method bodies and names. The model already shows promising results. The source code of code2seq is publicly available, making it possible to embed this model in any application. Although this model is still far from perfect, combining it with our research could already greatly reduce the manual refactoring effort required. The main deficiency of this model lies in that its limited to the method body and does currently not consider anything else in a method body. This method is flawed, because the meaning of method bodies depends heavily on their context. For instance, the body of the method \texttt{get()} in \texttt{ArrayList} does not make any sense in relation to its name without considering its context (class, inheritance hierarchy, etc.).

\subsection{Looking into other languages/paradigms}
In this study we describe duplicate code refactoring opportunities for object-oriented languages. We built a tool to refactor code clones in Java and used it to run our experiments.

Applying our experiments with other programming languages than just Java might result in valuable results. Refactoring opportunities are greatly dependent on coding conventions, which differ per language. Other languages might result in different results, which might result in different insights regarding the resolution of duplication problems found. We prioritized refactoring efforts based on Java, which might differ from the prioritization that can result from running our experiments with other programming languages.

In this study we focused only on the object-oriented paradigm because of the shared concepts. However, the problems that come with duplication in source code also appears in different programming languages. Because of that, more insights could be obtained when looking into automated refactoring opportunities for other paradigms. For instance, it might be valuable to look into the opportunities to reduce duplication in the functional domain. Dealing with code clones in the functional paradigm is pretty much an unexplored field and might hold valuable results.

\subsection{Running our experiments with a different set of software projects}
In our experiments we chose to use a GitHub based software corpus. This corpus contains a diversity of projects of many different sizes. We noticed that there is a lot of difference in the quality of these software systems: some systems had a lot of duplication and some did not have any duplication.

We think that there is value in running our experiments with different corpuses. We would, for instance, be interested in the results for industrial projects instead of open source software systems. We are curious to see whether the distributions are comparable, or whether they show large differences.

Furthermore, we think that there is value in running our experiments with a set of larger sized and more professionally developed open source systems. We noticed that in our corpus there were a lot of projects that have only few commits and contributors. We think it would be valuable to for instance perform our experiments with a set of larger open source systems, like the systems in the Apache ecosystem.

\subsection{Automatically refactoring code that is duplicated with a library}
One of the clone detection tools we analyzed in this study is Sisyphus \ref{eremondi2017sisyphus}. This clone detection tool searches a codebase for methods that are part of the Java standard libraries. There are definite automated refactoring opportunities here, automatically switching to the library implementation if available.

This doesn't have to be limited to just the Java standard library. Although using a new library for a single cloned library, we can also search the libraries the project are already uses. CloneRefactor is an excellent tool to expand for finding such clones with external libraries and refactoring the source code to use the library implementation if available. This is because CloneRefactor has scripts to gather all dependent libraries for Maven projects. It loads these libraries in order to be able to resolve symbols. If this would be expanded not only to resolve symbols but also to consider the clones between the analyzed project and its dependencies, we could find such refactoring opportunities.
